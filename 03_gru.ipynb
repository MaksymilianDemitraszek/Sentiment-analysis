{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle = False\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('/content/drive/MyDrive/datasets/movie.csv', sep=\",\")\n",
    "X = dataset[\"text\"]\n",
    "y = dataset[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, shuffle=shuffle)\n",
    "\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import History, EarlyStopping\n",
    "from keras.layers import Embedding, TextVectorization, Dense, LSTM, Input, Bidirectional\n",
    "\n",
    "vectorize_layer = TextVectorization(max_tokens=50000)\n",
    "vectorize_layer.adapt(X_train)\n",
    "\n",
    "history_Adam = History()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Vectorization\n",
    "model.add(Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "# Embedding\n",
    "model.add(Embedding(input_dim=len(vectorize_layer.get_vocabulary()), output_dim=64))\n",
    "\n",
    "\n",
    "model.add(Bidirectional(tf.keras.layers.GRU(32)))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, callbacks=[history_Adam, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_Adam.history['loss'], label = \"train\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"train\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test \")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import History, EarlyStopping\n",
    "from keras.layers import Embedding, TextVectorization, Dense, LSTM, Input, Bidirectional, GRU\n",
    "\n",
    "vectorize_layer = TextVectorization(max_tokens=50000)\n",
    "vectorize_layer.adapt(X_train)\n",
    "\n",
    "history_Adam = History()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Vectorization\n",
    "model.add(Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "# Embedding\n",
    "model.add(Embedding(input_dim=len(vectorize_layer.get_vocabulary()), output_dim=64))\n",
    "\n",
    "\n",
    "model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, callbacks=[history_Adam, early_stopping])\n",
    "\n",
    "plt.plot(history_Adam.history['accuracy'], label = \"train\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test \")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_Adam.history['loss'], label = \"train\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"train\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test \")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 5 - TwoLayer - Bidirectional GRU - with standarization\n",
    "https://www.dialog-21.ru/media/3380/arkhipenkoetal.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import History, EarlyStopping\n",
    "from keras.layers import Embedding, TextVectorization, Dense, LSTM, Input, Bidirectional, GRU\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=50000,\n",
    "    standardize=\"lower_and_strip_punctuation\"\n",
    "  )\n",
    "vectorize_layer.adapt(X_train)\n",
    "\n",
    "history_Adam = History()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Vectorization\n",
    "model.add(Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "# Embedding\n",
    "model.add(Embedding(input_dim=len(vectorize_layer.get_vocabulary()), output_dim=64))\n",
    "\n",
    "\n",
    "model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, callbacks=[early_stopping, history_Adam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_Adam.history['loss'], label = \"train\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"train\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test \")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 6 - TwoLayer - GRU - with standarization and bigrams\n",
    "https://www.dialog-21.ru/media/3380/arkhipenkoetal.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import History, EarlyStopping\n",
    "from keras.layers import Embedding, TextVectorization, Dense, LSTM, Input, Bidirectional, GRU\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=50000,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    ngrams = 2\n",
    "  )\n",
    "vectorize_layer.adapt(X_train)\n",
    "\n",
    "history_Adam = History()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Vectorization\n",
    "model.add(Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "# Embedding\n",
    "model.add(Embedding(input_dim=len(vectorize_layer.get_vocabulary()), output_dim=64))\n",
    "\n",
    "\n",
    "model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, callbacks=[early_stopping, history_Adam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_Adam.history['loss'], label = \"train\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"train\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test \")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
